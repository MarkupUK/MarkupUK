fil = new Array();
fil["0"]= "Chap2.html@@@Introduction@@@...";
fil["1"]= "Chap3.html@@@The Gaps Between XML and LaTeX@@@...";
fil["2"]= "Chap4.html@@@Methods to Convert XML to LaTeX@@@...";
fil["3"]= "Chap5.html@@@An Alternative Approach@@@...";
fil["4"]= "Chap6.html@@@Conclusion@@@...";
fil["5"]= "Sec1.html@@@xmltex@@@...";
fil["6"]= "Sec2.html@@@PassiveTeX@@@...";
fil["7"]= "Sec3.html@@@Pandoc@@@...";
fil["8"]= "Sec4.html@@@XSLT@@@...";
fil["9"]= "Sec5.html@@@Math Transform MathML to TeX@@@...";
fil["10"]= "Sec6.html@@@Transform XML to TeX@@@...";
fil["11"]= "Sec7.html@@@Issues@@@...";
fil["12"]= "ar01.html@@@XProc as a command-line application engine@@@This paper explores the use of XProc 3.0 in developing a set of command-line applications for converting XML documents into various derivatives. XProc is used as the core of the application and it experiments with building the application logic in XProc, including command-line handling and file/directory management. The paper proposes two design patterns that can be widely applied to use XProc effectively in developing command-line applications...";
fil["13"]= "ar01s01.html@@@Introduction@@@...";
fil["14"]= "ar01s02.html@@@What is XProc?@@@...";
fil["15"]= "ar01s03.html@@@The problem domain@@@...";
fil["16"]= "ar01s04.html@@@Is XProc a suitable language?@@@...";
fil["17"]= "ar01s05.html@@@Design pattern 1: Job tickets@@@...";
fil["18"]= "ar01s05s01.html@@@The job ticket@@@...";
fil["19"]= "ar01s06.html@@@Design pattern 2: Command line wrappers@@@...";
fil["20"]= "ar01s07.html@@@Wrap-up and conclusions@@@...";
fil["21"]= "ar02.html@@@Working with XML inside a web browser@@@Decentralization of data and applications with edge computing is coming outside the XML community. Can we revitalize web browsers and shift XML processing from the server side to the client side with added benefits of improved speed and low latency? Can we make XML an alternative to JavaScript and JSON development within web browsers? This requires client-side database technologies, client-side XML programming languages, support for XSLT, and powerful ways to address standalone XML documents as well as XML stored in document databases or XML supplied through cloud-based API calls. This calls for data abstraction and a unified data model within the web browser. This paper talks about two large projects aimed at solving the client-side equation of XML and putting XML on the map for web development again...";
fil["22"]= "ar02s01.html@@@Introduction@@@...";
fil["23"]= "ar02s02.html@@@Project Goals@@@...";
fil["24"]= "ar02s03.html@@@What new XML technologies are required?@@@...";
fil["25"]= "ar02s04.html@@@Technical Challenges@@@...";
fil["26"]= "ar02s05.html@@@The XML data model layer@@@...";
fil["27"]= "ar02s06.html@@@The XML user interface layer@@@...";
fil["28"]= "ar02s07.html@@@The XML program logic layer@@@...";
fil["29"]= "ar02s08.html@@@The resulting architecture of the XML edge platform@@@...";
fil["30"]= "ar02s09.html@@@The two projects@@@...";
fil["31"]= "ar02s10.html@@@Future development for the two projects@@@...";
fil["32"]= "ar02s11.html@@@Conclusion@@@...";
fil["33"]= "ar03.html@@@Markup UK Proceedings as CSS@@@Markup UK conference proceedings start life as DocBook XML markup and are formatted as PDF using XSL-FO that is generated by the DocBook XSLT 1.0 stylesheets. This paper discusses formatting the conference proceedings using CSS styles from the DocBook xslTNG XSLT 3.0 stylesheets...";
fil["34"]= "ar03s01.html@@@DocBook@@@...";
fil["35"]= "ar03s02.html@@@DocBook Stylesheets@@@...";
fil["36"]= "ar03s03.html@@@Comparing XSLT 1.0 and xslTNG Stylesheets@@@...";
fil["37"]= "ar03s03s01.html@@@Localisation@@@...";
fil["38"]= "ar03s03s02.html@@@Build system@@@...";
fil["39"]= "ar03s03s03.html@@@Syntax highlighting@@@...";
fil["40"]= "ar03s03s04.html@@@XSLT debugging@@@...";
fil["41"]= "ar03s03s05.html@@@Cover pages@@@...";
fil["42"]= "ar03s03s06.html@@@PDF bookmarks@@@...";
fil["43"]= "ar03s04.html@@@Current status@@@...";
fil["44"]= "ar03s05.html@@@Acknowledgements@@@...";
fil["45"]= "ar04.html@@@Enhancing Markup Quality Assurance with Automated Schema Visualization@@@The paper describes an XSD visualizer plugin that automates schema visualization and emphasizes the accuracy and completeness of element structure. It provides a comprehensive view of the inheritance hierarchy and actual element structure, allowing users to quickly identify potential errors and ensure the correctness and completeness of markup documents. This tool is useful for academics, software engineers, and end-users interested in enhancing their markup quality assurance practices through automated schema visualization with a specific focus on element structure...";
fil["46"]= "ar04s01.html@@@Introduction@@@...";
fil["47"]= "ar04s02.html@@@Background and Related Work@@@...";
fil["48"]= "ar04s03.html@@@Introducing the XSD Visualizer Plugin@@@...";
fil["49"]= "ar04s04.html@@@Key Features for Assessing Schema Quality@@@...";
fil["50"]= "ar04s04s01.html@@@Visualizing Inheritance Structure@@@...";
fil["51"]= "ar04s04s02.html@@@Providing Effective Element and Type Structure@@@...";
fil["52"]= "ar04s04s03.html@@@Jump-to-Code for Editing@@@...";
fil["53"]= "ar04s04s04.html@@@Future Development@@@...";
fil["54"]= "ar04s05.html@@@Enhancing the Schema Quality Workflow with Work-in-Progress Features@@@...";
fil["55"]= "ar04s05s01.html@@@Tree View for Exploring the Actual Structure@@@...";
fil["56"]= "ar04s05s02.html@@@Composite View for Understanding Complex Composition Structures@@@...";
fil["57"]= "ar04s06.html@@@Implementation Details of the XSD Visualizer Plugin@@@...";
fil["58"]= "ar04s07.html@@@Feedback and Future Development@@@...";
fil["59"]= "ar04s07s01.html@@@Support for Additional Schema Formats@@@...";
fil["60"]= "ar04s07s02.html@@@Potential Name Change to &quot;SchemaViz&quot;@@@...";
fil["61"]= "ar04s07s03.html@@@Port to Visual Studio Code@@@...";
fil["62"]= "ar04s07s04.html@@@HTML Export with SVG Graphics@@@...";
fil["63"]= "ar04s08.html@@@Conclusion@@@...";
fil["64"]= "ar05.html@@@Improving quality-critical XML workflows with XProc\u00A03.0 pipelines@@@Orchestrating complex XML pipelines has been a major topic of XML-related software development over the years. Comprehensive techniques have been developed to: Deliver high-quality resultsEnsure that the pipelines can be maintainedAllow the pipelines to be debugged for straightforward troubleshooting The quality demands for the workflow and the produced results can vary: For example, you may find a very maintainable pipeline producing documents with very low quality demands, e.g. the system producing the static website for your local sports club. On the other hand you might find documents with very high quality demands produced by a pipeline that is not easy to maintain and debug. And, of course, the relationship between the quality of the documents and the maintainability of the pipeline producing these documents may change over time. Implementing new quality demands for the documents might have a negative impact on the pipelines quality. And sometimes in the history of developing a pipeline expected to produce documents with high quality demands, you might even decide to start over, as new quality demands for the documents threaten to impair the quality of your pipeline. In this paper, we would like to report about a shared project of our two companies. We had to add new features to a well-established workflow producing documents in the medical sector that come with very high quality demands. As the existing workflow already had some pain points, we decided to start over and to refactor it. And we even decided to change the basic orchestrating technology: Since the existing workflow was based on a combination of Windows batch files calling different programs and some very elaborate XSLT stylesheets, we decided to use XProc\u00A03.0 to orchestrate the workflow, thus doing away with as much shell scripting as possible while keeping the XSLT stylesheets to do the actual transformations. As XProc\u00A03.0 is a relatively new technology for orchestrating document workflows, we think our project might be of some interest to people developing and/or maintaining pipelines for documents with high quality demands. We will first provide some background context for the produced documents and their actual usage to elaborate the specific quality demands. This will be followed by an overview of the existing workflow and a discussion on its pain points and new demands. We will then give an overview of the new XProc\u00A03.0 pipeline developed in the project and discuss some aspects of the used technology. The paperWe would like to thank the reviewers of our abstract for their very helpful comments. A special thank goes out to Geert\u00A0Bormans whose thoughtful remarks on the abstract helped to improved this paper significantly. concludes with the lessons learned in our project and the key takeaways of our project in a more general context of pipelines producing documents with high quality demands...";
fil["65"]= "ar05s01.html@@@Introduction and background@@@...";
fil["66"]= "ar05s01s01.html@@@About Thieme Compliance GmbH and patient education leaflets@@@...";
fil["67"]= "ar05s01s02.html@@@About &lt;xml-project /&gt; and XProc@@@...";
fil["68"]= "ar05s02.html@@@Introduction to existing batches@@@...";
fil["69"]= "ar05s02s01.html@@@Batch \u201Cfragengruppe_2_evidence\u201D@@@...";
fil["70"]= "ar05s02s02.html@@@Batch \u201Cfragengruppe_2_FHIR-Questionnaire\u201D@@@...";
fil["71"]= "ar05s03.html@@@Pain points of the existing batches@@@...";
fil["72"]= "ar05s03s01.html@@@Lacking of flexibility for inserting additional XSLT steps (in between)@@@...";
fil["73"]= "ar05s03s02.html@@@No easy way to debug the intermediate results of each XSLT step@@@...";
fil["74"]= "ar05s03s03.html@@@Too many tools means too many dependencies@@@...";
fil["75"]= "ar05s04.html@@@New requirements for next version@@@...";
fil["76"]= "ar05s04s01.html@@@Future-proof approach and improved maintainability by adding a separate orchestration layer@@@...";
fil["77"]= "ar05s04s02.html@@@Increased quality through validation of XML sources using T0 XSD as well as validation of XML results using specific versions of T0 DTD@@@...";
fil["78"]= "ar05s04s03.html@@@Increased quality by additional validation of XML results using Schematron@@@...";
fil["79"]= "ar05s04s04.html@@@Summarised, formatted and easily comprehensible log files@@@...";
fil["80"]= "ar05s04s05.html@@@Performance improvement by omitting unnecessary images from the Zip archive@@@...";
fil["81"]= "ar05s04s06.html@@@Limiting processing to specific sources from the source folder@@@...";
fil["82"]= "ar05s05.html@@@New system based on XProc\u00A03.0@@@...";
fil["83"]= "ar05s06.html@@@Takeaways@@@...";
fil["84"]= "ar05s06s01.html@@@Smooth transition to XProc\u00A03.0@@@...";
fil["85"]= "ar05s06s02.html@@@MorganaXProc-IIIse worked well and could even be improved over the course of the project@@@...";
fil["86"]= "ar05s06s03.html@@@Serialisation is now done by MorganaXProc and no longer by Saxon@@@...";
fil["87"]= "ar05s06s04.html@@@Performance problems with FHIR XML schema@@@...";
fil["88"]= "ar05s06s05.html@@@XProc pipeline optimisation by loading stylesheets only once at the beginning@@@...";
fil["89"]= "ar05s06s06.html@@@Feature request for XProc: please add &lt;p:validate-with-dtd&gt;@@@...";
fil["90"]= "ar06.html@@@Bridging the Gaps Between XML and TEX@@@There are established software solutions to convert from XML to TeX. Nevertheless, these approaches either limit the configurability of the TeX output or introduce a lot of programming effort. In this paper, we will discuss these methods and present an alternative approach that hopes to offer the greatest possible flexibility based on fixed conversions, an extensible configuration and the injection of XSLT, and that forms the basis for our Open Source typesetting system xerif...";
fil["91"]= "ar06s01.html@@@Acknowledgements@@@...";
fil["92"]= "ar07.html@@@Building a cloud-based visual operating system entirely based on XML@@@Interoperability and extensibility are keywords for XML. Why are we not seeing the same for software applications, web applications, mobile apps, and operating systems in general? Why can\u2019t I run an iPhone app om my Samsung TV? Why isn\u2019t Mac applications possible to run on my Windows computer? If we had interoperability and extensibility in a similar way that XML provides for data for software, we would not have any of these problems. Software would run across all types of devices, screen form factors, and operating systems \u2013 across desktop, mobile, smart TVs, and the infotainment systems of cars. This paper discusses how to use the XIOS/3 Edge Application Platform and the CloudBackend Singularity Database to create a new XML- and cloud-based operating system complete with productivity applications, software development tools, and a file system \u2013 including extensive support for XML. While CloudTop XML OS is still under development, this paper provides a snapshot of the current state of the implementation. It challenges the perception of what XML can be used for...";
fil["93"]= "ar07s01.html@@@Introduction@@@...";
fil["94"]= "ar07s02.html@@@Finding a cure to the chaotic software landscape@@@...";
fil["95"]= "ar07s03.html@@@What is CloudTop really?@@@...";
fil["96"]= "ar07s04.html@@@Changing the perception of a computer@@@...";
fil["97"]= "ar07s05.html@@@Verifying our assumptions@@@...";
fil["98"]= "ar07s06.html@@@Looking through a few of the sample applications built@@@...";
fil["99"]= "ar07s07.html@@@XMLPad - Data Manipulation and Transactions@@@...";
fil["100"]= "ar07s08.html@@@Kanban - Hierarchical Data Model@@@...";
fil["101"]= "ar07s09.html@@@Contacts - Key/values, Meta-data, and Datatypes@@@...";
fil["102"]= "ar07s10.html@@@CloudTop - Combining Applications into a Desktop@@@...";
fil["103"]= "ar08.html@@@Using TDD to produce High Quality XSLT@@@This paper explains the benefits we had in using TDD to developp a Markdown to XML transformer. It introduces TDD, Clean Code and Refactoring, and shows how to apply them to XSLT language...";
fil["104"]= "ar08s01.html@@@TDD : where does it comes from ?@@@...";
fil["105"]= "ar08s01s01.html@@@The TDD loop and the refactoring phase@@@...";
fil["106"]= "ar08s02.html@@@Writing a MarkDown to HTML converter with XSLT@@@...";
fil["107"]= "ar08s02s01.html@@@Feature definition@@@...";
fil["108"]= "ar08s02s02.html@@@Tooling@@@...";
fil["109"]= "ar08s02s03.html@@@Methods@@@...";
fil["110"]= "ar08s03.html@@@Implementation@@@...";
fil["111"]= "ar08s03s01.html@@@Level 1 titles@@@...";
fil["112"]= "ar08s03s02.html@@@Next titles and list items@@@...";
fil["113"]= "ar08s04.html@@@Pro and Cons of using TDD for XSLT development@@@...";
fil["114"]= "ar08s04s01.html@@@Bugs@@@...";
fil["115"]= "ar08s04s02.html@@@Baby steps@@@...";
fil["116"]= "ar08s04s03.html@@@Refactoring@@@...";
fil["117"]= "ar08s04s04.html@@@Code Coverage@@@...";
fil["118"]= "ar08s04s05.html@@@Data Coverage@@@...";
fil["119"]= "ar08s05.html@@@Conclusion@@@...";
fil["120"]= "ar09.html@@@Word processing is so last century@@@This presentation describes a journey of replacing WordPerfect with prodoc.dtd, a semantic authoring doctype; and how prodoc evolved to enable computer-assisted sense making, based on markup that formalizes knowledge flow analysis and modeling semantics. The paper also describes some of the challenges associated with multi-perspective decision making and techniques for negotiating and formalizing dynamic, natural-system ontologies. Lessons learned from WordNet and SUMO integrations are summarized. The paper concludes by suggesting that building editors and bots that use author-authored markup to digitize and amplify logic systems could, in many organizational settings, contribute to more-intelligent value optimizations and better long-term performance...";
fil["121"]= "ar09s01.html@@@Executive Summary@@@...";
fil["122"]= "ar09s02.html@@@What&apos;s computer-assisted sense making?@@@...";
fil["123"]= "ar09s02s01.html@@@Onto-what?@@@...";
fil["124"]= "ar09s02s02.html@@@Working with multiple languages, perspectives, and ontologies@@@...";
fil["125"]= "ar09s02s03.html@@@How prodoc helped make sense of big words@@@...";
fil["126"]= "ar09s02s04.html@@@Lessons learned@@@...";
fil["127"]= "ar09s03.html@@@The path to prodoc@@@...";
fil["128"]= "ar09s03s01.html@@@Bots hate word processing&apos;s ornery visually-oriented ontology@@@...";
fil["129"]= "ar09s03s02.html@@@Semantic markup to the rescue@@@...";
fil["130"]= "ar09s03s02s01.html@@@Separating structure and style@@@...";
fil["131"]= "ar09s03s02s02.html@@@Integrating lifecycle perspectives@@@...";
fil["132"]= "ar09s03s03.html@@@From semantic markup to semantic authoring@@@...";
fil["133"]= "ar09s03s03s01.html@@@Individual impacts@@@...";
fil["134"]= "ar09s03s03s02.html@@@Organizational impacts@@@...";
fil["135"]= "ar09s04.html@@@Document-level controls to capture and communicate meaning@@@...";
fil["136"]= "ar09s04s01.html@@@Author-driven structural changes@@@...";
fil["137"]= "ar09s04s02.html@@@Author-driven visual changes@@@...";
fil["138"]= "ar09s05.html@@@prodoc in practice@@@...";
fil["139"]= "ar09s05s01.html@@@@class \u2014 Authored class styles@@@...";
fil["140"]= "ar09s05s02.html@@@&lt;awkbuddy/&gt; \u2014 An interactive development environment block@@@...";
fil["141"]= "ar09s05s03.html@@@&lt;bbody/&gt;, &lt;branches/&gt;, &lt;branch/&gt; \u2014 Hierarchical tables@@@...";
fil["142"]= "ar09s05s04.html@@@&lt;colortest/&gt; \u2014 Automating accessible color negotiation pipelines@@@...";
fil["143"]= "ar09s05s05.html@@@&lt;h/&gt; \u2014 Depth-based headings because big headings are ugly@@@...";
fil["144"]= "ar09s05s06.html@@@&lt;kfam/&gt; \u2014 An element and generalized design language to make sense of knowledge flows from multiple perspectives@@@...";
fil["145"]= "ar09s05s06s01.html@@@kfam conceptual language@@@...";
fil["146"]= "ar09s05s06s02.html@@@kfam markup language@@@...";
fil["147"]= "ar09s05s06s03.html@@@kfam visual language@@@...";
fil["148"]= "ar09s05s06s04.html@@@kfam modeling@@@...";
fil["149"]= "ar09s05s07.html@@@&lt;music/&gt; \u2014 Rationalizing chord/ lyric pairings@@@...";
fil["150"]= "ar09s05s08.html@@@&lt;vcanvas/&gt; \u2014 Visualizing and comparing sets of value optimizations@@@...";
fil["151"]= "ar09s05s09.html@@@WordNet and SUMO integrations \u2014 Associating markup with dictionaries & formal logic@@@...";
fil["152"]= "ar09s05s09s01.html@@@Approach@@@...";
fil["153"]= "ar09s05s09s02.html@@@Findings & next steps@@@...";
fil["154"]= "ar09s06.html@@@Bottom-up negotiations to define shared meanings@@@...";
fil["155"]= "ar09s07.html@@@h1.dtd \u2014 Build your own prodoc@@@...";
fil["156"]= "ar09s07s01.html@@@h1.dtd summary@@@...";
fil["157"]= "ar10.html@@@Leveraging the Power of OpenAI and Schematron for Content Verification and Correction@@@The purpose of this presentation is to provide an overview of what AI is, the potential benefits of using AI with Schematron and SQF for content verification and correction, and some of the challenges we face when using AI for this purpose. AI (Artificial Intelligence) is a branch of computer science that studies and develops theories, methods, and technologies to allow machines to perceive, understand, and act in the world. AI is used to create algorithms that can learn, understand, and make decisions in complex environments. AI is used in many areas, including natural language processing, robotics, computer vision, data mining, and machine learning. OpenAI is a research laboratory dedicated to developing and deploying AI in order to solve complex problems. OpenAI has developed algorithms that use reinforcement learning and deep learning to solve problems in robotics, natural language processing, and computer vision. Schematron can be used to identify elements of a document and make assumptions about them, providing a powerful boost when used in conjunction with OpenAI algorithms. Using OpenAI algorithms with Schematron and SQF (Schematron Quick Fix) can help to automate the verification of the correctness, completeness, and accuracy of content. OpenAI algorithms can be used to automatically check and correct errors in content and markup. This can save time and money for content creators and publishers, as well as improving the accuracy of the content. However, there are challenges associated with using OpenAI for content verification and correction. OpenAI algorithms may not accurately identify errors in content, and may not be able to make corrections that are appropriate for the context. Additionally, OpenAI algorithms may not be able to detect errors that are due to cultural or regional differences in language. In conclusion, OpenAI can be a powerful tool for verifying and correcting content, but there are challenges associated with using OpenAI for this purpose. It is important to consider these challenges when using OpenAI for content verification and correction...";
fil["158"]= "ar10s01.html@@@Introduction@@@...";
fil["159"]= "ar10s02.html@@@Artificial Intelligence@@@...";
fil["160"]= "ar10s03.html@@@Generative Pre-trained Transformer(GPT)@@@...";
fil["161"]= "ar10s04.html@@@Schematron and AI@@@...";
fil["162"]= "ar10s05.html@@@Schematron Quick Fix and AI@@@...";
fil["163"]= "ar10s06.html@@@Implementation of AI in Schematron@@@...";
fil["164"]= "ar10s07.html@@@Examples of AI-driven Schematron and SQF Solutions@@@...";
fil["165"]= "ar10s07s01.html@@@Check text consistency@@@...";
fil["166"]= "ar10s07s02.html@@@Check text voice@@@...";
fil["167"]= "ar10s07s03.html@@@Answer to question@@@...";
fil["168"]= "ar10s07s04.html@@@Check the number of words@@@...";
fil["169"]= "ar10s07s05.html@@@Check if block of text should be a list@@@...";
fil["170"]= "ar10s07s06.html@@@User-Entry - Check technical terms@@@...";
fil["171"]= "ar10s08.html@@@Generate Fix Automatically@@@...";
fil["172"]= "ar10s09.html@@@Develop Schematron using AI@@@...";
fil["173"]= "ar10s10.html@@@Conclusion@@@...";
fil["174"]= "ar11.html@@@XQS: A Native XQuery Schematron Implementation@@@This paper will cover XQuery for Schematron (XQS) (pron. /\u025Bks\u02C8kju\u02D0z/),https://github.com/AndrewSales/XQS a Schematron processor being implemented in native \u2013 and na\u00EFve \u2013 XQuery. To the author&apos;s knowledge, there are no complete implementations publicly available at this time.Though note the experimental work in this area by David Maus: https://github.com/dmj/schematron-xquery. The purpose of the work is at least two-fold: to demonstrate the utility of an XQuery query language binding for arguably the primary quality assurance technology applicable to XML, and to provide a second &quot;reference&quot; implementation while work on the latest revision of the ISO standard proceeds. Although not required by the standardization process, it clearly helps to be able to answer the question standards authors should consider when new features present themselves: How would you implement that?...";
fil["175"]= "ar11s01.html@@@Background@@@...";
fil["176"]= "ar11s02.html@@@Rationale@@@...";
fil["177"]= "ar11s03.html@@@Design goals@@@...";
fil["178"]= "ar11s03s03.html@@@Portability@@@...";
fil["179"]= "ar11s04.html@@@Caveats@@@...";
fil["180"]= "ar11s04s01.html@@@Expansion and inclusion@@@...";
fil["181"]= "ar11s04s02.html@@@&quot;Native&quot;?@@@...";
fil["182"]= "ar11s04s03.html@@@Mandated XQuery QLB@@@...";
fil["183"]= "ar11s05.html@@@Approach@@@...";
fil["184"]= "ar11s05s01.html@@@Context is everything@@@...";
fil["185"]= "ar11s05s01s01.html@@@Document level@@@...";
fil["186"]= "ar11s05s01s02.html@@@Node level@@@...";
fil["187"]= "ar11s05s01s03.html@@@Assertion level@@@...";
fil["188"]= "ar11s06.html@@@Implementation@@@...";
fil["189"]= "ar11s06s01.html@@@Dynamically evaluated schema@@@...";
fil["190"]= "ar11s06s01s03.html@@@Rule processing@@@...";
fil["191"]= "ar11s06s01s04.html@@@Advisory notes@@@...";
fil["192"]= "ar11s06s02.html@@@Compiled schema@@@...";
fil["193"]= "ar11s07.html@@@Other features@@@...";
fil["194"]= "ar11s07s03.html@@@Maps, arrays and anonymous functions as variables@@@...";
fil["195"]= "ar11s08.html@@@Unit testing@@@...";
fil["196"]= "ar11s09.html@@@Evaluation@@@...";
fil["197"]= "ar11s10.html@@@Status of the work@@@...";
fil["198"]= "ar12.html@@@Quality in Formatted Documents@@@\u201CMarkup quality assurance\u201D is the theme for Markup UK 2023, but what does \u201Cquality\u201D mean when the markup is meant to be formatted for human consumption? When that markup is transformed from an original document in a completely different XML vocabulary? This presentation looks at different ways of assessing or assuring the quality of both the markup and the formatted document...";
fil["199"]= "ar12s01.html@@@Markup Quality@@@...";
fil["200"]= "ar12s01s01.html@@@XSL-FO@@@...";
fil["201"]= "ar12s01s02.html@@@CSS@@@...";
fil["202"]= "ar12s02.html@@@Formatted Quality@@@...";
fil["203"]= "ar12s02s01.html@@@Regression testing@@@...";
fil["204"]= "ar12s02s02.html@@@Automated analysis@@@...";
fil["205"]= "ar12s02s03.html@@@PDF/UA checking and remediation@@@...";
fil["206"]= "ar13.html@@@A Dependency Management Approach for Document and Data Transformation Projects@@@This talk introduces and evaluates the suitability of Apache Ivy as a dependency manager for document and data transformation projects, which is less common in these projects. The proposed solution will provide an optimized set of templates based on the development of Arousa and test common scenarios like dealing with local repositories and setting up a shared network repository. The approach has shown that it is suitable for dependency management on XSLT and XProc transformation projects, and the code samples will be shared for future reference. The initial experience with Arousa seems to back the validity of the solution, and the templates provided can help with the added complexity...";
fil["207"]= "ar13s01.html@@@Introduction@@@...";
fil["208"]= "ar13s02.html@@@Introducing Apache Ivy@@@...";
fil["209"]= "ar13s03.html@@@Starting with Arousa@@@...";
fil["210"]= "ar13s04.html@@@A bold experiment. How much time/effort does it take?@@@...";
fil["211"]= "ar13s05.html@@@Introducing the Arousa project structure@@@...";
fil["212"]= "ar13s06.html@@@Ivy abstraction. Introducing artifact types@@@...";
fil["213"]= "ar13s07.html@@@A Key difference with Maven@@@...";
fil["214"]= "ar13s08.html@@@Configuration chains@@@...";
fil["215"]= "ar13s09.html@@@The Ivy Cycle.@@@...";
fil["216"]= "ar13s10.html@@@Ivy flexibility (resolvers)@@@...";
fil["217"]= "ar13s11.html@@@Working with \u201COthers\u201D, the Dual resolvers@@@...";
fil["218"]= "ar13s12.html@@@A step further@@@...";
fil["219"]= "ar13s13.html@@@An advanced example@@@...";
fil["220"]= "ar13s14.html@@@Conclusions@@@...";
fil["221"]= "ar14.html@@@Tool-Based Transformations@@@This paper discusses the development of tools to explore and maintain XSLT, XQuery, and other markup-processing code. The tools described include FreqX, Xarcissus, and Eddie 2, which help to explore sample documents and large DTDs. The paper also covers XSLT DTD-coverage testing and encourages others to take a similar approach in developing tools to explore markup...";
fil["222"]= "ar14s05.html@@@Analyzing Existing Code@@@...";
fil["223"]= "ar14s06.html@@@Doing The Actual Work@@@...";
fil["224"]= "ar14s07.html@@@Conclusion@@@...";
fil["225"]= "bi04.html@@@Bibliography@@@...";
fil["226"]= "conformanceOverPerformance.html@@@Conformance over performance@@@...";
fil["227"]= "conformanceSuite.html@@@The conformance suite@@@...";
fil["228"]= "documentsAttribute.html@@@The documents attribute@@@...";
fil["229"]= "dynamicEvaluation.html@@@Dynamic evaluation@@@...";
fil["230"]= "evaluatingPatterns.html@@@Evaluating patterns@@@...";
fil["231"]= "futureWork.html@@@Future work@@@...";
fil["232"]= "graham-css-references.html@@@Bibliography@@@...";
fil["233"]= "introduction.html@@@Introduction@@@...";
fil["234"]= "marchand-references.html@@@Bibliography@@@...";
fil["235"]= "off-the-shelf-or-ad-hoc.html@@@Off-the-shelf tools and ad-hoc tools@@@...";
fil["236"]= "oxygen-main.html@@@Markup UK 2023 Proceedings@@@...";
fil["237"]= "phases.html@@@Project steps and phases@@@...";
fil["238"]= "programmaticAssembly.html@@@Evaluating schema components@@@...";
fil["239"]= "references.html@@@Bibliography@@@...";
fil["240"]= "sanchez-references.html@@@Bibliography@@@...";
fil["241"]= "userDefinedFunctions.html@@@User-defined functions@@@...";
fil["242"]= "ways-to-explore.html@@@Exploring Data@@@...";
var doStem = false;searchLoaded = true;